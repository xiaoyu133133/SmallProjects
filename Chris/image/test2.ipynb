{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78dd6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=r'D:\\ImageNet\\train'\n",
    "valid_path=r'D:\\ImageNet\\valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdf62ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms= v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6edb7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=ImageFolder(train_path, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de6ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c89a45",
   "metadata": {},
   "source": [
    "瓶颈层构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c46fbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion=4\n",
    "    def __init__(self, in_channels,hid_channels,stride=1,downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels,hid_channels,kernel_size=1,stride=1)\n",
    "        self.bn1=nn.BatchNorm2d(hid_channels)\n",
    "        self.conv2=nn.Conv2d(in_channels,hid_channels,kernel_size=3,stride=1)\n",
    "        self.bn2=nn.BatchNorm2d(hid_channels)\n",
    "        self.conv3=nn.Conv2d(in_channels,hid_channels,* self.expansion,kernel_size=1,stride=1)\n",
    "        self.bn3=nn.BatchNorm2d(hid_channels,*self.expansion)\n",
    "        self.relu=nn.ReLU(impalce=True)\n",
    "        self.downsample= downsample\n",
    "        self.stride=stride\n",
    "    def forward(self,x):\n",
    "        identity=x\n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.conv3(out)\n",
    "        out=self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            identity=self.downsample(x)\n",
    "\n",
    "        out +=identity\n",
    "        out=self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be704129",
   "metadata": {},
   "source": [
    "resnet主体\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, Bottleneck,num_classes=20):\n",
    "        super().__init__()\n",
    "        self.in_channels=64\n",
    "        self.conv1=nn.Conv2d(3,self.in_channels,kernal_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernal_size=3,stride=2,padding=1)\n",
    "        self.layer1=self._make_layer(Bottleneck,64,layer[0])\n",
    "        self.layer2=self._make_layer(Bottleneck,128,layer[1],stride=2)\n",
    "        self.layer3=self._make_layer(Bottleneck,256,layer[2],stride=2)\n",
    "        self.layer4=self._make_layer(Bottleneck,512,layer[3],stride=2)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc=nn.Linear(512,*Bottleneck.expansion,num_classes)\n",
    "def _make_layer(self,blocks,hid_channels,stride=1,dilate=False):\n",
    "     downsample=None\n",
    "     previous_dilation=self.dilation\n",
    "     if dilate:\n",
    "          self.dialtion*=stride\n",
    "          stride=1\n",
    "     if stride!=1 or self.in_channels != hid_channels*Bottleneck.expansion:\n",
    "        downsample=nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels,hid_channels*Bottleneck.expansion,stride),\n",
    "            nn.BatchNorm2d(hid_channels*Bottleneck.expansion),\n",
    "        ) \n",
    "     layers=[]\n",
    "     layers.append(Bottleneck(self.in_channels,hid_channels,stride,downsample)\n",
    "    )\n",
    "     self.in_channels=hid_channels*Bottleneck.expansion\n",
    "     for _ in range(1,blocks):\n",
    "         layers.append(\n",
    "             Bottleneck(self.in_channels,hid_channels,dilation=self.dialtion)\n",
    "         )\n",
    "     return nn.Sequential(*layers)\n",
    "def forward(self,x):\n",
    "    x=self.conv1(x)\n",
    "    x=self.bn1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.maxpool(x)\n",
    "     \n",
    "    x=self.layer1(x)\n",
    "    x=self.layer2(x)\n",
    "    x=self.layer3(x)\n",
    "    x=self.layer4(x)\n",
    "    \n",
    "    x=self.avgpool(x)\n",
    "    x=torch.flatten(x,1)\n",
    "    x=self.fc(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc8db7",
   "metadata": {},
   "source": [
    "训练模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,optimizer,train_loader):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "    total_loss += loss.item() * x.size(0)\n",
    "    preds = torch.max(outputs, 1)\n",
    "    correct += (preds == y).sum().item()\n",
    "    total += y.size(0)\n",
    "    pbar.set_postfix(loss=loss.item())\n",
    "    return total_loss / total, correct / total "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4f8d6",
   "metadata": {},
   "source": [
    "验证模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    pbar = tqdm(loader, desc=\"Validation\")\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.amp.autocast(device_type=\"cuda\"):\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    return total_loss / total, correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    train_ds = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transforms)\n",
    "    val_ds = datasets.ImageFolder(os.path.join(data_dir, \"valid\"), transform=val_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    train_accs, val_accs = [], []\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "        val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion)\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "  \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_acc)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if new_lr != current_lr:\n",
    "            print(f\"Learning rate reduced from {current_lr:.6f} to {new_lr:.6f}\")\n",
    "\n",
    "        print(f\"Train Loss {train_loss:.4f}, Train Acc {train_acc:.4f}\")\n",
    "        print(f\"Val Loss {val_loss:.4f}, Val Acc {val_acc:.4f}, LR {current_lr:.6f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_no_improve = 0\n",
    "            save_path = save_path_template.format(epoch=epoch+1, val_acc=val_acc)\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "            }, save_path)\n",
    "            print(f\"--> Best model saved with val_acc {best_val_acc:.4f} at {save_path}\")\n",
    "        \n",
    "\n",
    " \n",
    "    final_save_path = os.path.join(checkpoint_dir, \"final_model.pth\")\n",
    "    torch.save(model.state_dict(), final_save_path)\n",
    "    print(f\"Training finished. Final model saved at {final_save_path} with best val_acc {best_val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
